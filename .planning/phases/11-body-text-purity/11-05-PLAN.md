---
phase: 11-body-text-purity
plan: 05
type: execute
wave: 3
depends_on: ["11-03", "11-04"]
files_modified:
  - lib/rag/pipeline/writer.py
  - lib/rag/pipeline/runner.py
  - lib/rag/pipeline/__init__.py
autonomous: true

must_haves:
  truths:
    - "run_document_pipeline() executes document-level detectors (pre-pass) then page-level detectors (per-page loop)"
    - "Pipeline context flows between detectors (footnote bboxes → margin excluded_bboxes)"
    - "Writer routes classified blocks to correct output sections (body, footnotes, endnotes, citations, metadata)"
    - "DocumentOutput.write_files() produces flat files with suffix convention"
    - "Margins appear inline near original position in body text"
    - "Footnotes/endnotes appear in separate output file, not in body"
  artifacts:
    - path: "lib/rag/pipeline/runner.py"
      provides: "run_document_pipeline(), run_page_detectors(), run_document_detectors()"
      contains: "def run_document_pipeline"
    - path: "lib/rag/pipeline/writer.py"
      provides: "build_document_output(), format_body_text(), format_footnotes()"
      contains: "def build_document_output"
  key_links:
    - from: "lib/rag/pipeline/runner.py"
      to: "lib/rag/detection/registry.py"
      via: "get_registered_detectors(scope=DOCUMENT) and get_registered_detectors(scope=PAGE)"
      pattern: "get_registered_detectors"
    - from: "lib/rag/pipeline/runner.py"
      to: "lib/rag/pipeline/compositor.py"
      via: "resolve_conflicts() for page-level results"
      pattern: "resolve_conflicts"
    - from: "lib/rag/pipeline/writer.py"
      to: "lib/rag/pipeline/models.py"
      via: "DocumentOutput, BlockClassification, ContentType"
      pattern: "DocumentOutput"
---

<objective>
Build the pipeline runner (orchestrates detector execution) and writer (routes content to output files), completing the pipeline internals.

Purpose: Connects registry → detectors → compositor → output. This is the engine that process_pdf_structured() will call.
Output: `lib/rag/pipeline/runner.py` (pipeline execution), `lib/rag/pipeline/writer.py` (output routing)
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/11-body-text-purity/11-RESEARCH.md
@.planning/phases/11-body-text-purity/11-01-SUMMARY.md
@.planning/phases/11-body-text-purity/11-03-SUMMARY.md
@.planning/phases/11-body-text-purity/11-04-SUMMARY.md
@lib/rag/pipeline/models.py
@lib/rag/pipeline/compositor.py
@lib/rag/detection/registry.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pipeline runner</name>
  <files>lib/rag/pipeline/runner.py</files>
  <action>
Create `lib/rag/pipeline/runner.py`:

1. `run_document_pipeline(doc: "fitz.Document", output_format: str = "markdown", include_metadata: bool = False) -> DocumentOutput`:
   Main entry point. Orchestrates the two-phase pipeline:

   **Phase 1: Document-level pre-pass**
   - Get document-level detectors via `get_registered_detectors(scope=DetectorScope.DOCUMENT)`
   - Create shared `context: dict` (will accumulate toc_map, page_number_map, front_matter, etc.)
   - Run each document-level detector: `detector["func"](doc, context)`
   - Collect DetectionResult list

   **Phase 2: Page-level loop**
   - For each page in doc:
     - Get page-level detectors via `get_registered_detectors(scope=DetectorScope.PAGE)`
     - Extract raw page blocks via `page.get_text("dict")["blocks"]` → collect bboxes
     - Run each page-level detector: `detector["func"](page, page_num, context)`
       - page_num is 1-indexed
     - Collect DetectionResult list for this page
     - Call `classify_page_blocks()` to resolve conflicts for this page
     - Accumulate page results

   **Phase 3: Build output**
   - Call `build_document_output()` (from writer.py) with all classified blocks + context
   - Return DocumentOutput

   Error handling: If a detector raises an exception, log warning and skip it (graceful degradation). Pipeline should never halt because one detector fails.

2. `run_page_detectors(page, page_num: int, context: dict) -> List[DetectionResult]`:
   Helper that runs all page-level detectors on one page.

3. `run_document_detectors(doc, context: dict) -> List[DetectionResult]`:
   Helper that runs all document-level detectors.

Import all detection modules at the top of runner.py to ensure decorator registration happens:
```python
# Trigger detector registration
import lib.rag.detection.footnotes
import lib.rag.detection.margins
import lib.rag.detection.headings
import lib.rag.detection.page_numbers
import lib.rag.detection.toc
import lib.rag.detection.front_matter
```
  </action>
  <verify>
```bash
cd /home/rookslog/workspace/projects/zlibrary-mcp
uv run python -c "
from lib.rag.pipeline.runner import run_document_pipeline, run_page_detectors, run_document_detectors
print('Runner imports OK')
# Verify detectors are registered by import side-effect
from lib.rag.detection.registry import get_registered_detectors
d = get_registered_detectors()
assert len(d) == 6, f'Expected 6 detectors after runner import, got {len(d)}'
print(f'All {len(d)} detectors registered')
"
```
  </verify>
  <done>Pipeline runner orchestrates document-level pre-pass + page-level loop + compositor + output building</done>
</task>

<task type="auto">
  <name>Task 2: Create output writer</name>
  <files>lib/rag/pipeline/writer.py, lib/rag/pipeline/__init__.py</files>
  <action>
Create `lib/rag/pipeline/writer.py`:

1. `build_document_output(classified_pages: Dict[int, List[BlockClassification]], context: dict, include_metadata: bool = False) -> DocumentOutput`:
   - Iterates classified pages in page order
   - Routes blocks by ContentType:
     - BODY → body_text (preserve page order, join with newlines)
     - FOOTNOTE → footnotes string (formatted as numbered list per page)
     - ENDNOTE → endnotes string
     - MARGIN → body_text with inline annotation format: `[margin: {text}]` near original position
     - PAGE_NUMBER → stripped (not in any output)
     - HEADING → body_text as markdown heading (## level based on metadata)
     - TOC → document_metadata["toc"]
     - FRONT_MATTER → document_metadata["front_matter"]
     - CITATION → citations string
   - Builds document_metadata from context (toc_map, front_matter, title, page_number_map)
   - If include_metadata: builds processing_metadata with per-block classification details + confidence scores
   - Returns DocumentOutput

2. `format_body_text(body_blocks: List[BlockClassification], margin_blocks: List[BlockClassification]) -> str`:
   - Formats body blocks as continuous text
   - Inserts margin annotations inline near their original page position
   - Handles page breaks (optional: `\n\n---\n\n` between pages)

3. `format_footnotes(footnote_blocks: List[BlockClassification]) -> Optional[str]`:
   - Groups footnotes by page
   - Formats as: `## Page {N}\n\n1. {footnote text}\n2. ...`
   - Returns None if no footnotes

4. `format_metadata_sidecar(document_metadata: dict, processing_metadata: Optional[dict] = None) -> dict`:
   - Builds the JSON structure for `_meta.json`
   - Always includes: title, toc, front_matter info, page_count
   - Optionally includes: per-block classifications, confidence scores

Update `lib/rag/pipeline/__init__.py` to export `run_document_pipeline` from runner.
  </action>
  <verify>
```bash
cd /home/rookslog/workspace/projects/zlibrary-mcp
uv run python -c "
from lib.rag.pipeline.writer import build_document_output, format_body_text, format_footnotes
from lib.rag.pipeline.models import BlockClassification, ContentType, DocumentOutput
# Quick smoke test
body_block = BlockClassification(bbox=(72,100,500,120), content_type=ContentType.BODY, text='Hello world', confidence=1.0, detector_name='default', page_num=1)
fn_block = BlockClassification(bbox=(72,700,500,720), content_type=ContentType.FOOTNOTE, text='See reference 1', confidence=0.9, detector_name='footnotes', page_num=1)
output = build_document_output({1: [body_block, fn_block]}, context={})
assert 'Hello world' in output.body_text
assert output.footnotes is not None
assert 'See reference 1' in output.footnotes
print('Writer smoke test passed')
"
```
  </verify>
  <done>Writer routes blocks to correct output sections; margins inline in body; footnotes in separate section; metadata sidecar built</done>
</task>

</tasks>

<verification>
```bash
cd /home/rookslog/workspace/projects/zlibrary-mcp
uv run python -c "
from lib.rag.pipeline import run_document_pipeline
from lib.rag.pipeline.writer import build_document_output
from lib.rag.pipeline.runner import run_page_detectors, run_document_detectors
print('All pipeline components importable')
"
# Existing tests still pass
uv run pytest __tests__/python/ -x --tb=short -q 2>&1 | tail -5
```
</verification>

<success_criteria>
- run_document_pipeline() callable with a fitz.Document
- Two-phase execution: document pre-pass → page loop
- Writer correctly routes body, footnotes, margins, metadata
- Margins inline in body text as `[margin: ...]`
- Footnotes formatted separately by page
- Metadata sidecar includes TOC + front matter
- Pipeline gracefully handles detector failures
</success_criteria>

<output>
After completion, create `.planning/phases/11-body-text-purity/11-05-SUMMARY.md`
</output>
