---
phase: 11-body-text-purity
plan: 07
type: execute
wave: 5
depends_on: ["11-06", "11-02"]
files_modified:
  - __tests__/python/test_pipeline_integration.py
  - __tests__/python/test_recall_baseline.py
autonomous: true

must_haves:
  truths:
    - "End-to-end test processes a scholarly PDF and verifies multi-file output (body.md, _footnotes.md, _meta.json)"
    - "Recall regression test passes: no body text lost compared to pre-refactoring baseline"
    - "Confidence scores present in processing metadata when include_metadata=True"
    - "Footnote-margin dedup verified: no content appears in both footnotes and margin annotations"
    - "Front matter and TOC stripped from body, present in metadata sidecar"
  artifacts:
    - path: "__tests__/python/test_pipeline_integration.py"
      provides: "End-to-end integration tests for unified pipeline"
      contains: "test_scholarly_pdf_multi_file_output"
  key_links:
    - from: "__tests__/python/test_pipeline_integration.py"
      to: "lib/rag/orchestrator_pdf.py"
      via: "calls process_pdf_structured()"
      pattern: "process_pdf_structured"
    - from: "__tests__/python/test_recall_baseline.py"
      to: "test_files/ground_truth/body_text_baseline.json"
      via: "recall regression check against baseline"
      pattern: "body_text_baseline"
---

<objective>
Verify the complete pipeline with end-to-end integration tests and recall regression validation against the pre-refactoring baseline.

Purpose: This is the final verification plan. It confirms all three success criteria: (1) clean multi-file output, (2) confidence scoring, (3) zero recall loss.
Output: Integration test suite + passing recall regression
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/11-body-text-purity/11-CONTEXT.md
@.planning/phases/11-body-text-purity/11-02-SUMMARY.md
@.planning/phases/11-body-text-purity/11-06-SUMMARY.md
@lib/rag/orchestrator_pdf.py
@test_files/ground_truth/body_text_baseline.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create end-to-end integration tests</name>
  <files>__tests__/python/test_pipeline_integration.py</files>
  <action>
Create `__tests__/python/test_pipeline_integration.py` with:

1. `test_scholarly_pdf_multi_file_output()`:
   - Process a scholarly test PDF (one with footnotes, e.g., a Derrida or Heidegger excerpt)
   - Assert DocumentOutput has non-empty body_text
   - Assert footnotes is not None (scholarly PDFs have footnotes)
   - Assert document_metadata is populated with at least title or page_count
   - Write files to temp directory and verify suffix convention: `{stem}.md`, `{stem}_footnotes.md`, `{stem}_meta.json` exist

2. `test_confidence_scores_in_metadata()`:
   - Process a PDF with `include_metadata=True`
   - Assert processing_metadata contains per-block classifications
   - Assert each classification has a confidence float between 0.0 and 1.0
   - Assert detector_name is populated for each classification

3. `test_footnote_margin_no_duplication()`:
   - Process `margins_test_pages.pdf` (has both margins and footnotes)
   - Assert no text appears in BOTH footnotes output AND body margin annotations
   - Extract text from footnotes, extract margin annotations from body, assert zero intersection

4. `test_front_matter_toc_stripped_from_body()`:
   - Process a PDF that has front matter/TOC (if available in test corpus)
   - Assert front matter text does NOT appear in body_text
   - Assert front matter info IS in document_metadata

5. `test_headings_preserved_in_body()`:
   - Process any test PDF
   - Assert heading text appears in body_text as markdown headings (# or ## prefixed)

6. `test_page_numbers_stripped()`:
   - Process any test PDF
   - Assert page number strings do NOT appear as standalone lines in body_text

7. `test_backward_compat_process_pdf()`:
   - Call process_pdf() (old API)
   - Assert returns a string
   - Assert string is non-empty
   - Assert string matches body_text from process_pdf_structured()

Use `@pytest.mark.integration` marker. Use real test PDFs from `test_files/`.
  </action>
  <verify>
```bash
cd /home/rookslog/workspace/projects/zlibrary-mcp
uv run pytest __tests__/python/test_pipeline_integration.py -v --tb=short 2>&1 | tail -20
```
  </verify>
  <done>All 7 integration tests pass, verifying multi-file output, confidence scores, dedup, stripping, and backward compat</done>
</task>

<task type="auto">
  <name>Task 2: Run recall regression and fix any issues</name>
  <files>__tests__/python/test_recall_baseline.py</files>
  <action>
Run the recall regression tests from Plan 02 against the refactored pipeline:

1. Execute: `uv run pytest __tests__/python/test_recall_baseline.py -v`
2. If tests PASS: recall is preserved, done.
3. If tests FAIL:
   - Identify which PDFs have recall loss
   - Use `_process_pdf_legacy()` (preserved in Plan 06) to get old output
   - Diff old vs new to find missing lines
   - Fix the pipeline (likely a compositor or writer issue)
   - Re-run until all recall tests pass

4. After recall passes, run the FULL test suite:
   ```bash
   uv run pytest __tests__/python/ -v --tb=short
   ```
   Fix any regressions.

5. If recall test needed updating (e.g., baseline was generated before certain fixes), document why and update baseline with a comment noting the change date and reason.
  </action>
  <verify>
```bash
cd /home/rookslog/workspace/projects/zlibrary-mcp
# Recall regression
uv run pytest __tests__/python/test_recall_baseline.py -v --tb=short 2>&1 | tail -15
# Full test suite
uv run pytest __tests__/python/ -v --tb=short -q 2>&1 | tail -10
```
  </verify>
  <done>Zero recall loss verified against pre-refactoring baseline; full test suite passes</done>
</task>

</tasks>

<verification>
```bash
cd /home/rookslog/workspace/projects/zlibrary-mcp
# Complete verification: all Python tests
uv run pytest __tests__/python/ -v --tb=short 2>&1 | tail -30
# Quick smoke test of full pipeline
uv run python -c "
from lib.rag.orchestrator_pdf import process_pdf, process_pdf_structured
import glob
pdfs = glob.glob('test_files/*.pdf')
if pdfs:
    result = process_pdf_structured(pdfs[0], include_metadata=True)
    print(f'Body: {len(result.body_text)} chars')
    print(f'Footnotes: {len(result.footnotes) if result.footnotes else 0} chars')
    print(f'Metadata: {bool(result.document_metadata)}')
    print(f'Processing metadata: {bool(result.processing_metadata)}')
    print('SUCCESS: Full pipeline works')
"
```
</verification>

<success_criteria>
- All 7 integration tests pass
- Recall regression passes (zero body text loss)
- Confidence scores accessible in output metadata
- Footnote-margin dedup verified (no duplication)
- Full test suite passes with no regressions
- Phase 11 success criteria all satisfied:
  1. Multi-file output with clean body text + separated non-body content
  2. Confidence scores in metadata
  3. Zero recall loss
</success_criteria>

<output>
After completion, create `.planning/phases/11-body-text-purity/11-07-SUMMARY.md`
</output>
