---
phase: 07-eapi-migration
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - zlibrary/src/zlibrary/libasync.py
  - zlibrary/src/zlibrary/abs.py
  - zlibrary/src/zlibrary/profile.py
  - zlibrary/src/zlibrary/booklists.py
autonomous: true

must_haves:
  truths:
    - "AsyncZlib.search() uses EAPI instead of HTML GET + BeautifulSoup"
    - "AsyncZlib.download_book() uses EAPI /file endpoint instead of HTML page scraping"
    - "Profile download_history and get_limits use EAPI"
  artifacts:
    - path: "zlibrary/src/zlibrary/libasync.py"
      provides: "EAPI-backed search, full_text_search, download methods"
    - path: "zlibrary/src/zlibrary/abs.py"
      provides: "Simplified or replaced paginators using EAPI pagination"
    - path: "zlibrary/src/zlibrary/profile.py"
      provides: "EAPI-backed get_limits and download_history"
  key_links:
    - from: "zlibrary/src/zlibrary/libasync.py"
      to: "zlibrary/src/zlibrary/eapi.py"
      via: "self._eapi_client usage"
      pattern: "self\\._eapi"
---

<objective>
Replace all HTML scraping in the vendored zlibrary fork with EAPI calls. The four core files (libasync.py, abs.py, profile.py, booklists.py) currently use BeautifulSoup to parse HTML — rewrite them to use the EAPIClient from Plan 01.

Purpose: Eliminates Cloudflare-blocked HTML requests in the core library, restoring search/download/profile functionality.
Output: Vendored fork fully EAPI-powered with same public interface.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-eapi-migration/07-RESEARCH.md
@.planning/phases/07-eapi-migration/07-01-SUMMARY.md
@zlibrary/src/zlibrary/libasync.py
@zlibrary/src/zlibrary/abs.py
@zlibrary/src/zlibrary/profile.py
@zlibrary/src/zlibrary/booklists.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite libasync.py to use EAPIClient</name>
  <files>zlibrary/src/zlibrary/libasync.py</files>
  <action>
Modify `AsyncZlib` class in libasync.py:

1. **Init/Login**: After existing login (which gets remix_userid/remix_userkey cookies), create an `EAPIClient` instance (`self._eapi`). Call `self._eapi.get_domains()` to discover the correct EAPI domain. Store it.

2. **`search()` method**: Replace HTML GET + SearchPaginator with `self._eapi.search(message, **filters)`. Apply `normalize_eapi_search_response()` to results. Return normalized book list. Preserve the existing method signature and return format.

3. **`full_text_search()` method**: Route through `self._eapi.search()` with the same query (EAPI may not distinguish full-text vs title search). If the EAPI doesn't support full-text mode, document this as a known limitation and return regular search results with a note.

4. **`download_book()` method**: Replace HTML page scraping with:
   - Call `self._eapi.get_download_link(book_id, book_hash)` to get download URL
   - Stream-download the file using httpx (reuse existing download logic pattern)
   - Use the personal domain from domain discovery for download URLs
   - Preserve existing filename construction and output path logic

5. **`get_book_info()` method** (if exists): Replace with `self._eapi.get_book_info(id, hash)`.

6. **Remove BeautifulSoup imports** that are no longer needed. Keep any imports still used by retained code.

IMPORTANT: Preserve the public API (method names, parameter names, return types). Code that calls AsyncZlib must not need changes.
  </action>
  <verify>
`python -c "from zlibrary import AsyncZlib; print('import OK')"` succeeds.
Grep for BeautifulSoup in libasync.py returns no results: `grep -c 'BeautifulSoup' zlibrary/src/zlibrary/libasync.py` → 0.
  </verify>
  <done>libasync.py uses EAPIClient for all operations. No BeautifulSoup HTML parsing remains. Public API unchanged.</done>
</task>

<task type="auto">
  <name>Task 2: Simplify abs.py paginators and update profile.py + booklists.py</name>
  <files>zlibrary/src/zlibrary/abs.py, zlibrary/src/zlibrary/profile.py, zlibrary/src/zlibrary/booklists.py</files>
  <action>
1. **`abs.py`**: The `SearchPaginator`, `BooklistPaginator`, `DownloadsPaginator` classes parse HTML pages. Since EAPI handles pagination server-side (page/limit params), these classes are largely obsolete.
   - Keep `BookItem` class but simplify `_parse_book_page_soup` — if still needed for backward compat, add an `_from_eapi_dict(cls, data)` classmethod that creates a BookItem from normalized EAPI data.
   - Mark HTML-parsing paginator methods as deprecated or remove them if no other code imports them directly.
   - Remove BeautifulSoup-dependent code in the hot path.

2. **`profile.py`**: Replace `get_limits()` and `download_history()`:
   - `get_limits()` → call `eapi_client.get_profile()`, extract download limits from response
   - `download_history()` → call `eapi_client.get_downloaded()`, normalize results
   - These methods need access to the EAPIClient — accept it as a parameter or have it passed from AsyncZlib.

3. **`booklists.py`**: Replace `search_public()` / `search_private()`:
   - If EAPI has no booklist endpoint (per research: uncertain), either route through EAPI search with booklist-related query, or mark booklist browsing as degraded.
   - Remove HTML GET + BooklistPaginator usage.

IMPORTANT: Do NOT break `python_bridge.py` calls. Check what python_bridge imports from these modules and ensure those entry points still work.
  </action>
  <verify>
`grep -rc 'BeautifulSoup' zlibrary/src/zlibrary/abs.py zlibrary/src/zlibrary/profile.py zlibrary/src/zlibrary/booklists.py` shows 0 in hot-path code.
`uv run pytest __tests__/python/ -x -q 2>&1 | tail -5` — check for regressions.
  </verify>
  <done>Vendored fork has no BeautifulSoup HTML parsing in search/download/profile/booklist hot paths. All classes preserve their public interfaces.</done>
</task>

</tasks>

<verification>
1. `grep -r 'BeautifulSoup' zlibrary/src/zlibrary/libasync.py zlibrary/src/zlibrary/profile.py zlibrary/src/zlibrary/booklists.py` — zero matches
2. `python -c "from zlibrary import AsyncZlib; print(dir(AsyncZlib))"` — all public methods still exist
3. `uv run pytest __tests__/python/ -x -q` — existing tests (may need mock updates in Plan 04)
4. `npm run build` — TypeScript compilation clean
</verification>

<success_criteria>
- All 4 vendored fork files use EAPI instead of HTML scraping
- AsyncZlib public API unchanged (search, full_text_search, download_book)
- Profile and booklist functions use EAPI or are gracefully degraded
- No BeautifulSoup in hot paths
</success_criteria>

<output>
After completion, create `.planning/phases/07-eapi-migration/07-02-SUMMARY.md`
</output>
