---
phase: 04-python-monolith-decomposition
plan: 02
type: execute
wave: 2
depends_on: ["04-01"]
files_modified:
  - lib/rag/quality/__init__.py
  - lib/rag/quality/analysis.py
  - lib/rag/quality/pipeline.py
  - lib/rag/ocr/recovery.py
  - lib/rag/xmark/__init__.py
  - lib/rag/xmark/detection.py
  - lib/rag/processors/__init__.py
  - lib/rag/processors/pdf.py
  - lib/rag/processors/epub.py
  - lib/rag/processors/txt.py
  - lib/rag/orchestrator.py
  - lib/rag_processing.py
autonomous: true

must_haves:
  truths:
    - "lib/rag/ contains quality/, xmark/, processors/ subdirectories and orchestrator.py"
    - "rag_processing.py is a thin facade (~200 lines) containing only imports and re-exports"
    - "All 16 public API functions importable from lib.rag_processing"
    - "python_bridge.py works unchanged (from lib import rag_processing still resolves all functions)"
    - "uv run pytest and npm test both pass with zero test file modifications"
  artifacts:
    - path: "lib/rag/quality/analysis.py"
      provides: "detect_pdf_quality, _analyze_pdf_block, _determine_pdf_quality_category"
      contains: "__all__"
    - path: "lib/rag/quality/pipeline.py"
      provides: "QualityPipelineConfig, _stage_1/2/3 functions, _apply_quality_pipeline"
      contains: "QualityPipelineConfig"
    - path: "lib/rag/ocr/recovery.py"
      provides: "run_ocr_on_pdf, assess_pdf_ocr_quality, redo_ocr_with_tesseract"
      contains: "__all__"
    - path: "lib/rag/orchestrator.py"
      provides: "process_pdf, process_epub, process_txt, process_document, save_processed_text"
      contains: "__all__"
    - path: "lib/rag_processing.py"
      provides: "Thin facade re-exporting all public + semi-private API"
      contains: "from lib.rag"
  key_links:
    - from: "lib/rag/orchestrator.py"
      to: "lib/rag/processors/"
      via: "imports format-specific processors"
      pattern: "from lib.rag.processors"
    - from: "lib/rag/orchestrator.py"
      to: "lib/rag/quality/pipeline.py"
      via: "imports quality pipeline"
      pattern: "from lib.rag.quality"
    - from: "lib/python_bridge.py"
      to: "lib/rag_processing.py"
      via: "from lib import rag_processing"
      pattern: "rag_processing\\.process_"
---

<objective>
Extract remaining modules (quality, OCR recovery, xmark, processors, orchestrator) and convert rag_processing.py into a thin facade that re-exports all public API functions.

Purpose: Completes the monolith decomposition. After this plan, rag_processing.py contains zero implementation — only imports and re-exports. The python_bridge.py contract is preserved through the facade.

Output: Complete lib/rag/ package with all domain modules. rag_processing.py is a ~200-line facade. All tests pass unchanged.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-python-monolith-decomposition/04-01-SUMMARY.md
@.planning/phases/04-python-monolith-decomposition/04-RESEARCH.md
@lib/rag_processing.py
@lib/python_bridge.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extract quality, OCR recovery, xmark, and processor modules</name>
  <files>
    lib/rag/quality/__init__.py
    lib/rag/quality/analysis.py
    lib/rag/quality/pipeline.py
    lib/rag/ocr/recovery.py
    lib/rag/xmark/__init__.py
    lib/rag/xmark/detection.py
    lib/rag/processors/__init__.py
    lib/rag/processors/pdf.py
    lib/rag/processors/epub.py
    lib/rag/processors/txt.py
  </files>
  <action>
Extract remaining implementation VERBATIM from rag_processing.py:

**quality/analysis.py**: detect_pdf_quality, _analyze_pdf_block, _determine_pdf_quality_category. Imports from lib.rag.utils.constants for threshold constants.

**quality/pipeline.py**: QualityPipelineConfig class, _stage_1_statistical_detection, _stage_2_visual_analysis, _stage_3_ocr_recovery, _find_word_between_contexts, _apply_quality_pipeline. Imports from quality/analysis and detection modules as needed.

**ocr/recovery.py**: run_ocr_on_pdf, assess_pdf_ocr_quality, redo_ocr_with_tesseract. This module has external deps (pytesseract, ocrmypdf). Import TesseractNotFoundError, OCRDependencyError from lib.rag.utils.exceptions.

**xmark/detection.py**: _detect_xmarks_parallel, _detect_xmarks_single_page, _page_needs_xmark_detection_fast, _should_enable_xmark_detection_for_document.

**processors/pdf.py**: _format_pdf_markdown and PDF-specific formatting helpers. Imports from detection/ and quality/ as needed.

**processors/epub.py**: _epub_node_to_markdown, process_epub entry function. Imports from detection/toc.

**processors/txt.py**: process_txt entry function.

Each module: docstring, logger, __all__. Copy functions verbatim including all BUG-X FIX comments.

Replace moved code in rag_processing.py with imports. Run `uv run pytest && npm test` after extraction.
  </action>
  <verify>
    uv run pytest — all Python tests pass
    npm test — all Node.js tests pass
    python -c "from lib.rag_processing import detect_pdf_quality, QualityPipelineConfig, run_ocr_on_pdf, _detect_xmarks_parallel" — re-exports work after extraction
  </verify>
  <done>
    lib/rag/ contains quality/, xmark/, processors/ with implementation modules.
    ocr/recovery.py added to existing ocr/ directory.
    All modules under 500 lines.
  </done>
</task>

<task type="auto">
  <name>Task 2: Extract orchestrator and finalize rag_processing.py as facade</name>
  <files>
    lib/rag/orchestrator.py
    lib/rag/__init__.py
    lib/rag_processing.py
  </files>
  <action>
Extract the orchestrator — the last implementation code remaining in rag_processing.py:

**orchestrator.py**: process_pdf, process_epub (if not already in processors/epub.py), process_txt (if not already in processors/txt.py), process_document, save_processed_text. These are the 5 main entry points. Import from all lib.rag submodules as needed.

Note: process_pdf is the largest function (~470 lines, lines 4054-4523). It orchestrates detection, quality, formatting. It should import from detection/, quality/, processors/, ocr/ as needed.

After extracting orchestrator, convert rag_processing.py into a pure facade:

1. Remove ALL remaining implementation code
2. Add facade docstring: "RAG document processing - backward-compatible facade. All implementation lives in lib/rag/ subpackages."
3. Import and re-export EVERY function and class that tests or python_bridge.py import. This includes:
   - Public API: process_pdf, process_epub, process_txt, process_document, save_processed_text, detect_pdf_quality, run_ocr_on_pdf, assess_pdf_ocr_quality, redo_ocr_with_tesseract, detect_letter_spacing_issue, correct_letter_spacing, QualityPipelineConfig
   - Semi-private (imported by tests): _detect_footnotes_in_page, _calculate_page_normal_font_size, _is_superscript, _format_footnotes_markdown, _find_definition_for_marker, _footnote_with_continuation_to_dict, _extract_and_format_toc, _analyze_pdf_block, _extract_publisher_from_front_matter, _is_ocr_corrupted, _slugify, _html_to_text, infer_written_page_numbers
   - Constants: SUPPORTED_FORMATS, PROCESSED_OUTPUT_DIR
   - Exceptions: TesseractNotFoundError, FileSaveError, OCRDependencyError
   - Module-level objects that tests mock: pytesseract (if imported at module level)
4. Add __all__ listing all public names
5. Ensure `from lib import rag_processing` still allows `rag_processing.process_pdf(...)` etc.

CRITICAL: Check every test file's imports against the facade. Missing re-exports will cause silent test failures. Grep all test files for `from.*rag_processing import` and `import.*rag_processing` to verify complete coverage.

Also update lib/rag/__init__.py to re-export the full public API for direct package imports.

Run full test suite.
  </action>
  <verify>
    uv run pytest — all Python tests pass
    npm test — all Node.js tests pass
    wc -l lib/rag_processing.py — under 250 lines (thin facade)
    python -c "from lib import rag_processing; print(dir(rag_processing))" — shows all expected names
    python -c "from lib.rag_processing import process_pdf, process_epub, process_txt, process_document, save_processed_text, detect_pdf_quality" — all public API importable
    grep -rh "from lib.rag_processing import\|from lib import rag_processing" __tests__/ lib/python_bridge.py — list all external imports; verify every name exists in facade
  </verify>
  <done>
    rag_processing.py is a thin facade (~200 lines) with only imports and re-exports.
    orchestrator.py contains the 5 main entry points.
    All existing import paths work unchanged.
    python_bridge.py works without modification.
  </done>
</task>

</tasks>

<verification>
After both tasks:
1. `uv run pytest` — all Python tests pass (zero test file modifications)
2. `npm test` — all Node.js tests pass
3. `wc -l lib/rag_processing.py` — under 250 lines
4. `wc -l lib/rag/orchestrator.py` — contains process_pdf and other entry points
5. Every import in every test file resolves correctly
6. `python -c "from lib.python_bridge import *"` — python_bridge loads successfully
7. No module in lib/rag/ exceeds 500 lines (footnotes.py up to 700)
</verification>

<success_criteria>
- All remaining code extracted from rag_processing.py into domain modules
- rag_processing.py is a pure facade (~200 lines, zero implementation)
- Complete lib/rag/ package: utils/, detection/, quality/, ocr/, xmark/, processors/, orchestrator.py
- python_bridge.py unchanged and functional
- Full test suite passes with zero test file modifications
</success_criteria>

<output>
After completion, create `.planning/phases/04-python-monolith-decomposition/04-02-SUMMARY.md`
</output>
