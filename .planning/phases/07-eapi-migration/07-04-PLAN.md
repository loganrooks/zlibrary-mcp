---
phase: 07-eapi-migration
plan: 04
type: execute
wave: 3
depends_on: ["07-02", "07-03"]
files_modified:
  - lib/python_bridge.py
  - __tests__/python/test_python_bridge.py
  - __tests__/python/test_enhanced_metadata.py
  - __tests__/python/test_term_tools.py
  - __tests__/python/test_author_tools.py
  - __tests__/python/test_booklist_tools.py
autonomous: false

must_haves:
  truths:
    - "python_bridge.py creates and passes EAPIClient to all tool functions"
    - "All Python test mocks reflect EAPI response format"
    - "Health check endpoint validates EAPI connectivity"
    - "All 12 MCP tools work end-to-end via EAPI"
  artifacts:
    - path: "lib/python_bridge.py"
      provides: "EAPI-aware bridge with EAPIClient lifecycle management and health check"
    - path: "__tests__/python/test_python_bridge.py"
      provides: "Updated test mocks for EAPI response format"
  key_links:
    - from: "lib/python_bridge.py"
      to: "zlibrary/src/zlibrary/eapi.py"
      via: "EAPIClient instantiation and passing to tools"
      pattern: "EAPIClient"
    - from: "lib/python_bridge.py"
      to: "lib/term_tools.py"
      via: "passing eapi_client to search functions"
      pattern: "eapi_client"
---

<objective>
Wire the EAPI client through python_bridge.py, update all test mocks for EAPI responses, add a health check, and verify end-to-end functionality.

Purpose: Completes the migration by connecting the new EAPI layer to the MCP server entry point, ensuring all 12 tools work, and adding monitoring.
Output: Fully functional MCP server using EAPI, passing tests, with health check.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-eapi-migration/07-RESEARCH.md
@.planning/phases/07-eapi-migration/07-01-SUMMARY.md
@.planning/phases/07-eapi-migration/07-02-SUMMARY.md
@.planning/phases/07-eapi-migration/07-03-SUMMARY.md
@lib/python_bridge.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update python_bridge.py for EAPI client lifecycle</name>
  <files>lib/python_bridge.py</files>
  <action>
1. **EAPIClient lifecycle**: After AsyncZlib login succeeds, create an `EAPIClient` instance using the remix_userid and remix_userkey from the authenticated session. Call `get_domains()` to discover the correct EAPI domain. Store the client for reuse.

2. **Pass eapi_client to tool functions**: Update all calls to term_tools, author_tools, booklist_tools, and enhanced_metadata to pass the `eapi_client` instance as a parameter.

3. **`normalize_book_details()`**: Update to handle EAPI response format. The `hash`/`book_hash` field is now directly available from EAPI (no URL extraction needed). Ensure `bookDetails` objects passed to `download_book_to_file` include the hash field.

4. **`get_book_metadata_complete()`**: Replace HTML fetch + enhanced_metadata parsing with EAPI call via `eapi_client.get_book_info(book_id, book_hash)`. Map EAPI JSON to existing return format.

5. **Health check function**: Add `async def eapi_health_check()` that:
   - Calls `eapi_client.search("test", limit=1)`
   - Verifies response has `success: 1` and non-empty `books` array
   - Returns `{status: "healthy", transport: "eapi"}` or `{status: "unhealthy", error: ...}`
   - This satisfies Success Criterion #4 (automated health check)

6. **Remove dead HTML-fetching code**: Remove any functions that directly fetch HTML pages for data extraction (keep RAG-related functions that process local files).

IMPORTANT: The `process_document()` and `process_document_for_rag()` functions are LOCAL file processing — do NOT modify these.
  </action>
  <verify>
`python -c "import lib.python_bridge; print('OK')"` — imports work.
`grep -c 'BeautifulSoup' lib/python_bridge.py` — should be 0 or minimal (only if used for non-API purposes).
  </verify>
  <done>python_bridge.py creates EAPIClient, passes it to all tools, includes health check, no HTML scraping in API hot path.</done>
</task>

<task type="auto">
  <name>Task 2: Update all Python test mocks for EAPI format</name>
  <files>__tests__/python/test_python_bridge.py, __tests__/python/test_enhanced_metadata.py, __tests__/python/test_term_tools.py, __tests__/python/test_author_tools.py, __tests__/python/test_booklist_tools.py</files>
  <action>
Update test mocks across all Python test files to reflect EAPI response format:

1. **test_python_bridge.py**: Update mocked responses from HTML-parsed format to EAPI JSON format. Mock `EAPIClient` methods (search, get_book_info, get_download_link, etc.) instead of HTTP GET requests. Verify `normalize_book_details()` produces correct output from EAPI input.

2. **test_enhanced_metadata.py**: Replace HTML string fixtures with EAPI JSON response fixtures. Mock `eapi_client.get_book_info()` instead of HTTP GET + BeautifulSoup parse. Verify metadata extraction from JSON matches expected output format.

3. **test_term_tools.py**: Mock `eapi_client.search()` instead of HTTP GET + HTML parsing. Verify term search returns normalized book list.

4. **test_author_tools.py**: Mock `eapi_client.search()` instead of HTTP GET + HTML parsing. Verify author search with name validation still works.

5. **test_booklist_tools.py**: Update for degraded booklist behavior if EAPI doesn't support booklists, or mock EAPI search for booklist queries.

For each test file:
- Replace HTML string fixtures with EAPI JSON dict fixtures
- Mock EAPIClient methods instead of httpx/aiohttp GET calls
- Keep the same assertions on output format (the normalized output should be identical)
- Run tests after each file update to catch issues incrementally

Run: `uv run pytest __tests__/python/ -x -v` after all updates.
  </action>
  <verify>
`uv run pytest __tests__/python/ -v` — all tests pass.
`uv run pytest __tests__/python/ --tb=short 2>&1 | grep -E 'passed|failed'` — zero failures.
  </verify>
  <done>All Python tests pass with EAPI-format mocks. Zero test failures.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete EAPI migration: EAPIClient, vendored fork rewrite, lib/ tools migration, python_bridge wiring, test updates, health check</what-built>
  <how-to-verify>
1. Build the project: `npm run build`
2. Run all tests: `npm test`
3. Run Python tests specifically: `uv run pytest __tests__/python/ -v`
4. Run Node.js tests: `node --experimental-vm-modules node_modules/jest/bin/jest.js`
5. Verify no BeautifulSoup in hot paths: `grep -r 'BeautifulSoup' zlibrary/src/zlibrary/libasync.py zlibrary/src/zlibrary/profile.py lib/term_tools.py lib/author_tools.py lib/enhanced_metadata.py lib/python_bridge.py`
6. If you have Z-Library credentials, test live: set ZLIBRARY_EMAIL and ZLIBRARY_PASSWORD env vars, run `npm start` and use an MCP client to call `search_books` with query "python"
  </how-to-verify>
  <resume-signal>Type "approved" if all tests pass and the EAPI migration is verified, or describe any issues found.</resume-signal>
</task>

</tasks>

<verification>
1. `npm run build` — TypeScript compiles cleanly
2. `uv run pytest __tests__/python/ -v` — all Python tests pass
3. `node --experimental-vm-modules node_modules/jest/bin/jest.js` — all Node.js tests pass
4. `grep -r 'BeautifulSoup' zlibrary/src/zlibrary/libasync.py lib/python_bridge.py lib/term_tools.py lib/author_tools.py lib/enhanced_metadata.py` — zero matches
5. Health check function exists and is callable
</verification>

<success_criteria>
- python_bridge.py manages EAPIClient lifecycle
- All Python test mocks updated for EAPI format
- All tests pass (zero regressions)
- Health check function validates EAPI connectivity
- No BeautifulSoup in any search/browse/metadata hot path
- Human verification of end-to-end functionality
</success_criteria>

<output>
After completion, create `.planning/phases/07-eapi-migration/07-04-SUMMARY.md`
</output>
