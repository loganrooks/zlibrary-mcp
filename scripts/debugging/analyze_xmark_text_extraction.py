#!/usr/bin/env python3
"""
Analyze how X-marked text is extracted and why garbled detector doesn't flag it.

Investigation: User correctly questions why garbled detector doesn't catch X-marked regions.
Hypothesis: Granularity mismatch - X-marks affect 1-2 words, detector analyzes entire region.
"""

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from lib.rag_processing import _analyze_pdf_block
from lib.garbled_text_detection import detect_garbled_text_enhanced, GarbledDetectionConfig
from lib.rag_data_models import PageRegion
import fitz

def analyze_derrida_page():
    """Analyze the specific page with known X-marked word 'is'."""
    pdf_path = Path('test_files/derrida_pages_110_135.pdf')

    if not pdf_path.exists():
        print(f"PDF not found: {pdf_path}")
        return

    doc = fitz.open(pdf_path)

    # Page with "is" crossed out - analyze all blocks
    page = doc[0]  # First page (0-indexed)

    print("="*80)
    print("DERRIDA PAGE ANALYSIS - X-marked word 'is'")
    print("="*80)
    print(f"\nPage 1 (PDF index 0)")
    print(f"Dimensions: {page.rect.width} x {page.rect.height}\n")

    blocks = page.get_text("dict")['blocks']
    text_blocks = [b for b in blocks if b.get('type') == 0]

    print(f"Total text blocks: {len(text_blocks)}\n")

    for idx, block in enumerate(text_blocks):
        print(f"\n{'-'*80}")
        print(f"BLOCK {idx + 1}/{len(text_blocks)}")
        print(f"{'-'*80}")

        # Analyze block
        analysis = _analyze_pdf_block(block, return_structured=True)

        if isinstance(analysis, PageRegion):
            text = analysis.get_text()
        else:
            text = analysis['text']

        print(f"Text length: {len(text)} chars")
        print(f"First 200 chars: {text[:200]!r}")

        # Check for X-mark symbols
        if ')(' in text or '~' in text or ')' in text:
            print(f"\nüîç FOUND X-MARK SYMBOLS!")
            print(f"   Contains ')(': {'Yes' if ')(' in text else 'No'}")
            print(f"   Contains '~': {'Yes' if '~' in text else 'No'}")

            # Find the exact location
            for i, char in enumerate(text):
                if char in '()~':
                    context_start = max(0, i - 20)
                    context_end = min(len(text), i + 20)
                    print(f"   Context around '{char}': ...{text[context_start:context_end]}...")

        # Run garbled detection on this block
        config = GarbledDetectionConfig(
            symbol_density_threshold=0.25,
            repetition_threshold=0.7,
            min_text_length=10
        )

        result = detect_garbled_text_enhanced(text, config)

        print(f"\nGARBLED DETECTION:")
        print(f"  Is garbled: {result.is_garbled}")
        print(f"  Confidence: {result.confidence:.3f}")
        print(f"  Flags: {result.flags}")
        print(f"  Metrics:")
        print(f"    Symbol density: {result.metrics.get('symbol_density', 0):.3f} (threshold: 0.25)")
        print(f"    Entropy: {result.metrics.get('entropy', 0):.3f}")
        print(f"    Repetition: {result.metrics.get('repetition_ratio', 0):.3f} (threshold: 0.7)")

        if result.is_garbled:
            print(f"\n  ‚úÖ GARBLED DETECTED")
        else:
            print(f"\n  ‚ùå NOT FLAGGED AS GARBLED")

        # Character analysis
        total_chars = len(text)
        if total_chars > 0:
            alpha = sum(1 for c in text if c.isalpha())
            digits = sum(1 for c in text if c.isdigit())
            spaces = sum(1 for c in text if c.isspace())
            symbols = total_chars - alpha - digits - spaces

            print(f"\nCHARACTER BREAKDOWN:")
            print(f"  Total: {total_chars}")
            print(f"  Alphabetic: {alpha} ({alpha/total_chars:.1%})")
            print(f"  Digits: {digits} ({digits/total_chars:.1%})")
            print(f"  Spaces: {spaces} ({spaces/total_chars:.1%})")
            print(f"  Symbols: {symbols} ({symbols/total_chars:.1%})")

    doc.close()


def analyze_word_level_detection():
    """Test garbled detection at WORD level vs PARAGRAPH level."""
    print(f"\n\n{'='*80}")
    print("GRANULARITY ANALYSIS: Word vs Paragraph Level")
    print("="*80)

    # Simulate paragraph with ONE crossed-out word
    clean_paragraph = "This is a normal philosophical argument about Being and consciousness. " * 5
    xmarked_word = ")("  # Corrupted "is"
    mixed_paragraph = clean_paragraph.replace("is a", f"{xmarked_word} a", 1)  # Replace first occurrence

    print(f"\n1. CLEAN PARAGRAPH (no X-marks):")
    print(f"   Text: {clean_paragraph[:100]}...")
    result_clean = detect_garbled_text_enhanced(clean_paragraph)
    print(f"   Garbled: {result_clean.is_garbled}")
    print(f"   Symbol density: {result_clean.metrics.get('symbol_density', 0):.3f}")

    print(f"\n2. PARAGRAPH WITH ONE X-MARKED WORD:")
    print(f"   Text: {mixed_paragraph[:100]}...")
    result_mixed = detect_garbled_text_enhanced(mixed_paragraph)
    print(f"   Garbled: {result_mixed.is_garbled}")
    print(f"   Symbol density: {result_mixed.metrics.get('symbol_density', 0):.3f}")

    # Calculate expected symbol density
    total_chars = len(mixed_paragraph)
    symbol_chars = 2  # ")(" = 2 symbols
    expected_density = symbol_chars / total_chars

    print(f"\n   Expected symbol density: {expected_density:.3f}")
    print(f"   Garbled threshold: 0.25")
    print(f"   Ratio: {expected_density / 0.25:.1%} of threshold")

    if not result_mixed.is_garbled:
        print(f"\n   ‚ùå NOT FLAGGED: Symbol density too low (diluted by clean text)")
        print(f"   EXPLANATION: One 2-char X-mark in {total_chars}-char paragraph = {expected_density:.1%} symbols")
        print(f"                This is {expected_density / 0.25:.0%} of the 25% threshold")

    print(f"\n3. JUST THE X-MARKED WORD:")
    xmarked_only = ")("
    result_word = detect_garbled_text_enhanced(xmarked_only)
    print(f"   Text: '{xmarked_only}'")
    print(f"   Garbled: {result_word.is_garbled}")
    print(f"   Symbol density: {result_word.metrics.get('symbol_density', 0):.3f}")

    if result_word.is_garbled:
        print(f"   ‚úÖ FLAGGED: When isolated, X-mark IS detected as garbled")

    print(f"\n{'='*80}")
    print("CONCLUSION:")
    print("="*80)
    print("The garbled detector IS working correctly at its granularity level.")
    print("Issue: It operates on REGIONS (paragraphs), not WORDS.")
    print("")
    print("X-marked word in isolation: 100% symbols ‚Üí GARBLED ‚úÖ")
    print("X-marked word in paragraph: ~2% symbols ‚Üí NOT GARBLED ‚úÖ (diluted)")
    print("")
    print("Solution options:")
    print("1. Run Stage 2 independently (current fix) - Detects visual X-marks")
    print("2. Add word-level garbled detection - More complex, may not help")
    print("3. Lower threshold to 2% - Would flag normal punctuation")
    print("")
    print("Recommendation: Keep Stage 2 independent (best solution)")
    print("="*80)


if __name__ == '__main__':
    analyze_derrida_page()
    analyze_word_level_detection()
